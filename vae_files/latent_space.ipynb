{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Latent graph code and KNeighbors",
   "id": "e6a1993080b98776"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-20T15:16:23.214593Z",
     "start_time": "2024-08-20T15:15:57.558365Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn #nn = neural network layer\n",
    "import torch.nn.functional as F # access to nn functions\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import nilearn.image\n",
    "import nilearn.plotting\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.lines as mlines\n",
    "print(torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")",
   "id": "955786788c3dafbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Input non-labeled training and diagnosis-labeled test data",
   "id": "aac2ade5c9c43f21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_csv = pd.read_csv('model_data/train_brain_labels_deid.csv', index_col=0)\n",
    "train_parquet_scaled = pd.read_parquet('model_data/train_brain_data_deid_scaled.parquet')\n",
    "test_csv = pd.read_csv('model_data/test_brain_labels_deid.csv', index_col=0)\n",
    "test_parquet_scaled = pd.read_parquet('model_data/test_brain_data_deid_scaled.parquet')\n",
    "nd_csv = pd.read_csv('model_data/nd_brain_labels_deid.csv', index_col=0)\n",
    "nd_parquet_scaled = pd.read_parquet('model_data/nd_brain_data_deid_scaled.parquet')"
   ],
   "id": "5aed76031d6be489"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Input shortened labeled dataset\n",
    "\n",
    "Retain only data with diagnosis of ad, bvftd, cu, or dlb, and age and sex information"
   ],
   "id": "34fb4eeeeb4364ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nd_csv_short = pd.read_csv('model_data/nd_filtered_data.csv', index_col=0)",
   "id": "a15a7a13f48cf343"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load brain mask and prepare it",
   "id": "58ebcc0efe84c263"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "brain_mask = nilearn.image.load_img('model_data/brain_mask.nii')\n",
    "img_data = np.zeros(brain_mask.shape)\n",
    "vec = train_parquet_scaled.iloc[0, 0]\n",
    "nz_indices = np.ma.nonzero(brain_mask.get_fdata())"
   ],
   "id": "5e59f21c2bb83c8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Hyperparameters and k matrix initialization",
   "id": "64c00d99bf8f4df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 16\n",
    "radius = 2\n",
    "k_normalized = torch.load('model_data/tensor_k_norm.pt')"
   ],
   "id": "538427be94e199a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Custom dataset",
   "id": "c197a2fbf5a83bf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomLoader(Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        super(CustomLoader, self).__init__()\n",
    "        \n",
    "        self.images = images # parquet\n",
    "        self.transform = transform\n",
    "\n",
    "        self.n_samples = self.images.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images.iloc[idx].copy()\n",
    "        image = np.array(image)\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.to(torch.float32)\n",
    "        image = image.unsqueeze(0)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ],
   "id": "43f5db68da562fff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load datasets using cutom dataset loader",
   "id": "55868f252341a2d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_data = CustomLoader(images=train_parquet_scaled, transform=None)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size = BATCH_SIZE, num_workers = 0, shuffle=True)\n",
    "\n",
    "test_data = CustomLoader(images=test_parquet_scaled, transform=None)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size = BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "\n",
    "nd_data = CustomLoader(images=nd_parquet_scaled, transform=None)\n",
    "nd_loader = DataLoader(dataset=nd_data, batch_size=BATCH_SIZE, num_workers=0, shuffle=False)"
   ],
   "id": "acad7eca77e68c66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Graph convolution method",
   "id": "7d955f0738e1e1cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 264,
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, k):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.d1 = nn.Conv1d(in_dim, out_dim, kernel_size=1)\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        device = imgs.device\n",
    "        x = self.d1(imgs)\n",
    "        x = x.cpu() @ self.k.cpu()\n",
    "        x = x.to(device)\n",
    "        return x"
   ],
   "id": "9ec7d5bc07c99778"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Graph convolutional network block",
   "id": "8ceb5c8bdddf25be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 470,
   "source": [
    "class GCNBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, k):\n",
    "        super(GCNBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.GC1 = GraphConv(in_dim, out_dim, self.k)\n",
    "        self.GC2 = GraphConv(out_dim, out_dim, self.k)\n",
    "        self.bn1 = nn.BatchNorm1d(out_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(out_dim)\n",
    "    def forward(self, x):\n",
    "        identity = x.mean(axis=1, keepdim = True)\n",
    "        out = self.GC1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.tanh(out) #out = F.relu(out)\n",
    "        out = self.GC2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = out + identity\n",
    "        #out = F.relu(out)  #testing\n",
    "        return out"
   ],
   "id": "1c5c76d94af4a4f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Encoder of the Variational autoencoder",
   "id": "53b30be061eaf439"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 471,
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim, conv_dim, lin_dim, latent_dims, k, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.k = k\n",
    "        self.device = device\n",
    "        self.GCBlock = GCNBlock(in_dim, conv_dim, self.k)\n",
    "\n",
    "        self.Lin1 = nn.Linear(conv_dim * self.k.shape[0], lin_dim)\n",
    "        self.Lin2 = nn.Linear(lin_dim, latent_dims)\n",
    "        self.Lin3 = nn.Linear(lin_dim, latent_dims)\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        #self.N.loc = self.N.loc.to(device)\n",
    "        #self.N.scale = self.N.scale.to(device)\n",
    "        self.KL = 0.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = self.GCBlock(x)\n",
    "        x = F.tanh(x) #x = F.relu(x)\n",
    "        \n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.Lin1(x)\n",
    "        x = F.tanh(x) #x = F.relu(x)\n",
    "\n",
    "        mu = self.Lin2(x)\n",
    "        sigma = torch.exp(self.Lin3(x))\n",
    "        z = mu + sigma * self.N.sample(mu.shape).to(self.device)\n",
    "        self.KL = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        return z"
   ],
   "id": "840467b7eda8a2a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Decoder of the variational autoencoder",
   "id": "5972c19f762d95d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 472,
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_dim, conv_dim, lin_dim,  latent_dims, k):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.k = k\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(latent_dims, lin_dim),\n",
    "            nn.Tanh(), #nn.relu(True),\n",
    "            nn.Linear(lin_dim, conv_dim * self.k.shape[0]), \n",
    "            nn.Tanh() #nn.relu(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(conv_dim, self.k.shape[0]))\n",
    "\n",
    "        self.decoder_conv = GCNBlock(conv_dim, in_dim, self.k)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        \n",
    "        x = self.decoder_conv(x)\n",
    "        return x"
   ],
   "id": "eb3c6ddbad1c0982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Variational Autoencoder class",
   "id": "9f3275c9f0d6687a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 473,
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_dim, conv_dim, lin_dim, latent_dims, k, device):\n",
    "        super(VAE, self).__init__()\n",
    "        self.device = device\n",
    "        self.k = k\n",
    "        self.encoder = Encoder(in_dim, conv_dim, lin_dim, latent_dims, self.k, self.device)\n",
    "        self.decoder = Decoder(in_dim, conv_dim, lin_dim, latent_dims, self.k)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ],
   "id": "b460baf462858c9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Optimizer and variational autoencoder initialization and hyperparameters",
   "id": "1f4c890b96c56219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 474,
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "latent_dims = 16\n",
    "vae = VAE(1, 8, 256, latent_dims=latent_dims, k=k_normalized, device=device)\n",
    "\n",
    "vae.to(device)\n",
    "total_epochs = 0\n",
    "\n",
    "lr = 1e-5\n",
    "optim = torch.optim.Adam(vae.parameters(), lr=lr)"
   ],
   "id": "ded279dc5bd63441"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load trained variational autoencoder model and optimizer",
   "id": "457fb1a00ece620a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vae.load_state_dict(torch.load('model_data/2gc_16dim_model_scaled.pt'))\n",
    "vae.eval()\n",
    "optim.load_state_dict(torch.load('model_data/2gc_16dim_optim_scaled.pt'))"
   ],
   "id": "d7e14c622acb7ae9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Encode train dataset",
   "id": "9b647ebcd444ffed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_encoded_samples = []\n",
    "for sample in tqdm(train_data):\n",
    "    img = sample.unsqueeze(0).to(device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img = vae.encoder(img)\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    train_encoded_samples.append(encoded_sample)\n",
    "train_encoded_samples = pd.DataFrame(train_encoded_samples, index=train_csv.index)\n",
    "train_encoded_samples.to_csv('model_data/16dim_train_embeddings_scaled.csv')"
   ],
   "id": "d623f54f4163d733"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Encode train dataset",
   "id": "6c5412c96bda3acf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_encoded_samples = []\n",
    "for sample in tqdm(test_data):\n",
    "    img = sample.unsqueeze(0).to(device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img = vae.encoder(img)\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    test_encoded_samples.append(encoded_sample)\n",
    "test_encoded_samples = pd.DataFrame(test_encoded_samples, index=test_csv.index)\n",
    "test_encoded_samples.to_csv('model_data/16dim_test_embeddings_scaled.csv')"
   ],
   "id": "859691e400e05fd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Encode labeled dataset",
   "id": "a12e13b3287db0b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nd_encoded_samples = []\n",
    "for sample in tqdm(nd_data):\n",
    "    img = sample.unsqueeze(0).to(device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img = vae.encoder(img)\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    nd_encoded_samples.append(encoded_sample)"
   ],
   "id": "7277cef349752719"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Take data are kept in shortened dataset",
   "id": "b6b85292e5b48ebf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nd_encoded_samples = pd.DataFrame(nd_encoded_samples, index=nd_csv.index)\n",
    "common_indices = nd_encoded_samples.index.isin(nd_csv_short.index)\n",
    "nd_encoded_samples_short = nd_encoded_samples[common_indices]\n",
    "nd_encoded_samples.to_csv('model_data/model_16dim_full_embeddings_scaled.csv')\n",
    "nd_encoded_samples_short.to_csv('model_data/model_16dim_short_test_embeddings_scaled.csv')"
   ],
   "id": "dfa10ffc932d9f30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c73521783bc26852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Remove sex and age label",
   "id": "6ce8a12a9d7136be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "desired_columns = ['age_at_scan', 'ad', 'bvftd', 'cu', 'dlb']\n",
    "nd_csv_nsex = nd_csv_short[desired_columns].copy()\n",
    "nd_removed_columns = list(set(nd_csv_nsex.columns) - set(desired_columns))\n",
    "for col in nd_removed_columns:\n",
    "    if col in nd_csv_short:\n",
    "        mask = (nd_csv_nsex[col] != 1)\n",
    "        mask = mask.loc[nd_csv_nsex.index]\n",
    "        nd_csv_nsex = nd_csv_nsex[mask]\n",
    "nd_csv_nage = nd_csv_nsex.drop(axis=1, columns='age_at_scan')"
   ],
   "id": "9b6a0014fc9b4452"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Use tools from Neurology-AI-Program profile, svlite repository\n",
    "\n",
    "Code from: https://github.com/Neurology-AI-Program/svlite"
   ],
   "id": "b7adcf677abc9c1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from svlite.svlite.data_structures import VectorTable, AnnotationTable\n",
    "from svlite.svlite.graphical import KNeighbors\n",
    "import networkx as nx"
   ],
   "id": "c8f89cdf267e0f0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vector_table = VectorTable(nd_encoded_samples_short.values, index_col=nd_csv_nsex.index)\n",
    "ann_table = AnnotationTable(nd_csv_nsex)\n",
    "knn_latent = KNeighbors(n_neighbors=8, metric='cosine')\n",
    "knn_latent.populate(vector_table, ann_table)\n",
    "nx.write_gexf(knn_latent, 'Graphs/vae_scaled_filtered.gexf')"
   ],
   "id": "76b507bbf3dc99b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Full labels version\n",
    "\n",
    "Include: ['age_at_scan', 'ad', 'bvftd', 'cbs', 'cu', 'dlb', 'lvppa', 'nfppa', 'pca', 'ppaos', 'psp', 'sd']"
   ],
   "id": "6064100cedcdca71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "desired_columns = ['age_at_scan', 'ad', 'bvftd', 'cbs', 'cu', 'dlb', 'lvppa', 'nfppa', 'pca', 'ppaos', 'psp', 'sd']\n",
    "nd_csv_nsex_full = nd_csv[desired_columns].copy()\n",
    "nd_removed_columns = list(set(nd_csv_nsex_full.columns) - set(desired_columns))\n",
    "\n",
    "for col in nd_removed_columns:\n",
    "    if col in nd_csv:\n",
    "        mask = (nd_csv_nsex_full[col] != 1)\n",
    "        mask = mask.loc[nd_csv_nsex_full.index]\n",
    "        nd_csv_nsex_full = nd_csv_nsex_full[mask]"
   ],
   "id": "aeeec4a66ca0a1ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vector_table_full = VectorTable(nd_encoded_samples.values, index_col=nd_csv_nsex_full.index)\n",
    "ann_table_full = AnnotationTable(nd_csv_nsex_full)\n",
    "knn_latent_full = KNeighbors(n_neighbors=8, metric='cosine')\n",
    "knn_latent_full.populate(vector_table_full, ann_table_full)\n",
    "nx.write_gexf(knn_latent_full, 'Graphs/vae_scaled_full.gexf')"
   ],
   "id": "e9c3ccf018d5527a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### KNeighbors from svlite and ROC curves",
   "id": "9673b78075e5b716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "knn_sv = KNeighbors(n_neighbors=8, metric='cosine')\n",
    "knn_sv.populate(vector_table_full, ann_table_full)\n",
    "\n",
    "odds = knn_sv.neighbor_votes(metric='odds_ratio')\n",
    "pvals = knn_sv.neighbor_votes(metric='fisher', fisher_alternative='greater')"
   ],
   "id": "66da2437a521f47f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "node_color_map = {'ad': \"#006400\", 'bvftd': \"#FF7F50\", 'cbs': 'pink', 'cu': \"#838B8B\", 'dlb': \"#ffd700\", 'lvppa': \"#00ff00\", 'nfppa': \"#8B4513\", 'pca': \"#00ffff\", 'ppaos': \"#ff1493\", 'psp': \"#a020f0\", 'sd': \"#1e90ff\", 'total': 'black'}",
   "id": "3e57aab7632ab792"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "col_order = ['cu', 'dlb', 'pca', 'ad', 'lvppa', 'sd', 'bvftd', 'nfppa', 'cbs', 'psp', 'total']\n",
    "degen_cols = [c for c in col_order if c not in ['cu', 'total']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "handles = []\n",
    "for pt in col_order[:-1]:\n",
    "    fpr, tpr, _ = roc_curve(ann_table_full.data[pt], odds[pt])\n",
    "    score = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, c=node_color_map[pt], lw=2, ls='-')\n",
    "    handle = mlines.Line2D(\n",
    "        [], [],\n",
    "        color=node_color_map[pt],\n",
    "        marker='o',\n",
    "        fillstyle='full',\n",
    "        label=f'{pt} (AUC={np.round(score, 2)})',\n",
    "        linestyle=\"None\",\n",
    "        markersize=10\n",
    "    )\n",
    "    handles.append(handle)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], ls='--', c='black', lw=2)\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.legend(handles=handles, bbox_to_anchor=(1.05, 0.00), loc=4, shadow=True, frameon=True, fontsize=10, ncols=1,\n",
    "          edgecolor='black')"
   ],
   "id": "f283eb59241927a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Neighborhood graph visualization",
   "id": "6933bd1bc4310d2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "selected_node = vector_table_full.data.index[0]\n",
    "neighborhood_subgraph = knn_latent_full.neighborhood_view(selected_node)"
   ],
   "id": "6cb8317f86d4529c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "node_labels = {}\n",
    "for node in neighborhood_subgraph.nodes:\n",
    "    label_series = ann_table_full.data.loc[node, ann_table_full.binary_annotation_cols]\n",
    "    label_info = label_series[label_series == 1].index.tolist()\n",
    "    node_labels[node] = label_info[0] if label_info else 'unlabeled'\n",
    "colors = [node_color_map.get(knn_latent_full.nodes[node]['node_color'], 'gray') for node in neighborhood_subgraph.nodes]\n",
    "\n",
    "nx.draw(neighborhood_subgraph, labels=node_labels, with_labels=True, node_color=colors, edge_color='gray')\n",
    "plt.show()"
   ],
   "id": "382b88702bead3de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Principal Component Analysis (PCA) comparison",
   "id": "cf5cbee2e4cb1711"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pca = PCA(n_components=16, whiten=True)\n",
    "pca_train_res = pca.fit_transform(train_parquet_scaled)\n",
    "pca_res = pca.transform(nd_parquet_scaled)"
   ],
   "id": "c9285a56c4924e90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "vector_table_pca = VectorTable(pca_res, index_col=nd_csv_nsex_full.index)\n",
    "ann_table_pca = AnnotationTable(nd_csv_nsex_full)\n",
    "knn_latent_pca = KNeighbors(n_neighbors=8, metric='cosine')\n",
    "knn_latent_pca.populate(vector_table_pca, ann_table_pca)\n",
    "nx.write_gexf(knn_latent_pca, 'Graphs/pca_scaled_full.gexf')"
   ],
   "id": "546b9209a23020b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "odds = knn_latent_pca.neighbor_votes(metric = 'odds_ratio')\n",
    "pvals = knn_latent_pca.neighbor_votes(metric = 'fisher', fisher_alternative = 'greater')"
   ],
   "id": "400346e75c279008"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "col_order = ['cu', 'dlb', 'pca', 'ad', 'lvppa', 'sd', 'bvftd', 'nfppa', 'cbs', 'psp', 'total']\n",
    "degen_cols = [c for c in col_order if c not in ['cu', 'total']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6, 6))\n",
    "handles = []\n",
    "for pt in col_order[:-1]:\n",
    "    fpr, tpr, _ = roc_curve(ann_table_pca.data[pt], odds[pt])\n",
    "    score = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, c = node_color_map[pt], lw = 2, ls = '-')\n",
    "    handle = mlines.Line2D(\n",
    "        [], [], \n",
    "        color = node_color_map[pt], \n",
    "        marker = 'o', \n",
    "        fillstyle = 'full', \n",
    "        label = f'{pt} (AUC={np.round(score, 2)})', \n",
    "        linestyle = \"None\",\n",
    "        markersize = 10\n",
    "    )\n",
    "    handles.append(handle)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], ls = '--', c = 'black', lw = 2)\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.legend(handles = handles, bbox_to_anchor=(1.05, 0.00), loc = 4, shadow = True, frameon = True, fontsize = 10, ncols = 1, edgecolor ='black')"
   ],
   "id": "d5d2019e2ec28461"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
